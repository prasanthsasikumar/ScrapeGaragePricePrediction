{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63fc938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sub_dataset.csv and print the headers\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def print_csv_headers(file_path):\n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        headers = next(reader)  # Read the first row as headers\n",
    "        print(\"Headers:\", headers)\n",
    "\n",
    "def check_nulls(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    null_counts = df[['Model', 'Mileage', 'Price']].isnull().sum()\n",
    "    print(\"Null counts in 'Model', 'Mileage' & 'Price':\")\n",
    "    print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_null_mileage(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_cleaned = df.dropna(subset=['Mileage'])\n",
    "    df_cleaned.to_csv(file_path, index=False)\n",
    "    print(f\"Rows with NaN in 'Mileage' removed. Remaining rows: {len(df_cleaned)}\")\n",
    "\n",
    "def format_mileage_column(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Mileage'] = df['Mileage'].replace({r'\\D': ''}, regex=True).astype(float)\n",
    "    df_cleaned = df[df['Mileage'] > 0]\n",
    "    df_cleaned.to_csv(file_path, index=False)\n",
    "    print(f\"Rows with 'Mileage' as 0 removed. Remaining rows: {len(df_cleaned)}\")\n",
    "\n",
    "def remove_null_price(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_cleaned = df.dropna(subset=['Price'])\n",
    "    df_cleaned.to_csv(file_path, index=False)\n",
    "    print(f\"Rows with NaN in 'Price' removed. Remaining rows: {len(df_cleaned)}\")\n",
    "\n",
    "def format_price_column(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Price'] = df['Price'].replace({r'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "    df_cleaned = df[df['Price'] > 0]\n",
    "    df_cleaned.to_csv(file_path, index=False)\n",
    "    print(f\"Rows with 'Price' as 0 removed. Remaining rows: {len(df_cleaned)}\")\n",
    "\n",
    "#function to classify the damage description as stolen(yes/no) and save it in a new column. Based on the description, if it contains 'stolen','ignition' or Vandalised in any case then it is classified as stolen, otherwise not stolen.\n",
    "def classify_stolen(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Stolen'] = df['Damage description'].str.contains('stolen|ignition|vandalised', case=False, na=False).replace({True: 'Yes', False: 'No'})\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(\"Stolen classification added to the dataset.\")\n",
    "\n",
    "def format_model_year(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    last_segment = df['Link'].str.extract(r'/([^/]+)/?$')[0]\n",
    "    df['Model Year'] = last_segment.str.extract(r'^(\\d{4})')\n",
    "    df['Model Year'] = pd.to_numeric(df['Model Year'], errors='coerce')\n",
    "    df = df.dropna(subset=['Model Year'])\n",
    "    df['Model Year'] = df['Model Year'].astype(int)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Model Year extracted and added. Remaining rows: {len(df)}\")\n",
    "\n",
    "#function to classify the damage description as light, medium or heavy based on the description. If it contain 'Light', 'Medium' or 'Heavy' in any case then it is classified as light, medium or heavy respectively, otherwise classified as 'Light'.\n",
    "def classify_damage_severity(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Damage Severity'] = df['Damage description'].str.extract(r'(Light|Medium|Heavy)', flags=re.IGNORECASE, expand=False).fillna('Light')\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(\"Damage severity classification added to the dataset.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de197e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'sub_dataset.csv'\n",
    "classify_damage_severity(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1839a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Price\n",
      "8916  2025-05-16    NaN\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.read_csv('../data/processed/merged_car_data.csv')\n",
    "filtered_entries = df_merged[df_merged['Link'].str.contains('000000000007179855', na=False)]\n",
    "#print just the date, price\n",
    "filtered_entries = filtered_entries[['Date', 'Price']]\n",
    "print(filtered_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb01e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
